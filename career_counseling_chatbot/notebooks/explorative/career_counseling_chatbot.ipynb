{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c43e35",
   "metadata": {},
   "source": [
    "\n",
    "# Career Counseling Chatbot (LLM + RAG)\n",
    "\n",
    "This notebook demonstrates how to create a retrieval-augmented chatbot using data from berufsberating.ch, OpenAI embeddings, ChromaDB, and LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7468b2",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1445dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import queue\n",
    "import PyPDF2\n",
    "import textwrap\n",
    "import keyboard\n",
    "import threading\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import (\n",
    "            ChatPromptTemplate,\n",
    "            SystemMessagePromptTemplate,\n",
    "            HumanMessagePromptTemplate)\n",
    "\n",
    "import openai\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import _play_with_simpleaudio\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Path\n",
    "path = '/home/ec2-user/SageMaker/career_counseling_chatbot'\n",
    "\n",
    "\n",
    "# Show working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7002910",
   "metadata": {},
   "source": [
    "## Load occupation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333774b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load occupation data\n",
    "with open(path + '/data/processed/berufsberatung_occupations_de.json', \n",
    "          'r', \n",
    "          encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare documents for embedding\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "# Track any issues for reporting\n",
    "issues = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    try:\n",
    "        occupation_name = item.get('Name', f\"Unbekannt_{i}\")\n",
    "        # print(f\"Processing {occupation_name}...\")\n",
    "\n",
    "        # Extract related occupations\n",
    "        related_occupations = []\n",
    "        if 'Related' in item and isinstance(item['Related'], list):\n",
    "            for related in item['Related']:\n",
    "                if isinstance(related, dict) and 'name' in related:\n",
    "                    related_occupations.append(related['name'])\n",
    "        \n",
    "        # Format related occupations section\n",
    "        related_section = \"\"\n",
    "        if related_occupations:\n",
    "            related_section = \"Verwandte Berufe: \" + \", \".join(related_occupations)\n",
    "        else:\n",
    "            related_section = \"Verwandte Berufe: Keine verwandten Berufe angegeben\"\n",
    "\n",
    "        # Safely extract fields with defaults for missing values\n",
    "        # Create a comprehensive document from all relevant fields\n",
    "        content = f\"\"\"\n",
    "        Name: {item.get('Name', 'NA')}\n",
    "        Beschreibung: {item.get('Description', 'NA')}\n",
    "        Bildungstypen: {item.get('Bildungstypen', 'NA')}\n",
    "        Berufsfelder: {item.get('Berufsfelder', 'NA')}\n",
    "        Tätigkeiten: {item.get('Tätigkeiten', 'NA')}\n",
    "        Ausbildung: {item.get('Ausbildung', 'NA')}\n",
    "        Voraussetzungen: {item.get('Voraussetzungen', 'NA')}\n",
    "        Weiterbildung: {item.get('Weiterbildung', 'NA')}\n",
    "        Berufsverhältnisse: {item.get('Berufsverhältnisse', 'NA')}\n",
    "        {related_section}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add document to list\n",
    "        documents.append(content)\n",
    "        \n",
    "        # Create metadata with safe extraction\n",
    "        metadata = {\n",
    "            'id': item.get('ID', f\"unknown_{i}\"),\n",
    "            'name': item.get('Name', 'Unknown Occupation'),\n",
    "            'url': item.get('URL', 'NA'),\n",
    "            'related_ids': [related.get('id', 'NA') for related in item.get('Related', [])]\n",
    "        }\n",
    "        metadatas.append(metadata)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing item {i}: {str(e)}\"\n",
    "        print(f\"WARNING: {error_msg}\")\n",
    "        issues.append(error_msg)\n",
    "        # Continue with next item rather than failing the entire process\n",
    "\n",
    "print(f\"Loaded {len(documents)} occupation documents.\")\n",
    "if issues:\n",
    "    print(f\"Encountered {len(issues)} issues during processing.\")\n",
    "\n",
    "# Example: Display the first document\n",
    "# if documents:\n",
    "#    print(\"\\nExample of prepared document:\")\n",
    "#    print(documents[0][:500] + \"...\")\n",
    "\n",
    "# Store documents and metadata for later use\n",
    "occupation_data = {\n",
    "    'documents': documents,\n",
    "    'metadatas': metadatas,\n",
    "    'processing_issues': issues\n",
    "}\n",
    "\n",
    "# Save the prepared data\n",
    "with open(path + '/data/processed/occupation_data_prepared.json', 'w', \n",
    "          encoding='utf-8') as f:\n",
    "    json.dump(occupation_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Data preparation complete and saved to occupation_data_prepared.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d1830",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether embeddings are already created\n",
    "if os.path.exists(path + \"/data/processed/chroma_db\") and \\\n",
    "    os.listdir(path + \"/data/processed/chroma_db\"):\n",
    "    print(\"Embeddings already exist. Skipping embedding creation.\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Create embeddings\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        # Store embeddings in Chroma vectorstore\n",
    "        vectorstore = Chroma.from_texts(documents, \n",
    "                                        embeddings, \n",
    "                                        persist_directory=path + \\\n",
    "                                        \"/data/processed/chroma_db\")\n",
    "\n",
    "        # Persist vectorstore\n",
    "        vectorstore.persist()\n",
    "\n",
    "        # Print sucess message\n",
    "        print(\"Embeddings created and stored successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating and storing embeddings: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dca48d",
   "metadata": {},
   "source": [
    "## Load embeddings from vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Load the vectorstore from the persisted directory\n",
    "vectorstore = Chroma(persist_directory=path + \"/data/processed/chroma_db\", \n",
    "                     embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6999658",
   "metadata": {},
   "source": [
    "## Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a896587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0)\n",
    "\n",
    "# Define the system prompt (instructions for the AI)\n",
    "system_template = \"\"\"\n",
    "Du bist ein hilfreicher Berufsberater der Nutzern bei der Karriereplanung hilft.\n",
    "Antworte präzise, klar und freundlich basierend auf folgenden Kontext:\n",
    "\n",
    "{context}\n",
    "\n",
    "Wenn in den Kontext-Informationen keine passende Antwort gefunden wird,\n",
    "antworte ehrlich, dass du die Information nicht hast.\n",
    "\"\"\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Define the human prompt (user's question)\n",
    "human_template = \"{question}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# Combine system and human prompts into a ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "# Initialize RetrievalQA Chain with the custom prompt\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": chat_prompt}\n",
    ")\n",
    "\n",
    "print(\"Chatbot is ready for use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66071d88",
   "metadata": {},
   "source": [
    "## Functions to query the chatbot and get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the chatbot response\n",
    "def format_text(text, width=80):\n",
    "    lines = []\n",
    "    for line in text.split('\\n'):\n",
    "        while len(line) > width:\n",
    "            split_index = line.rfind(' ', 0, width)\n",
    "            if split_index == -1:\n",
    "                split_index = width\n",
    "            lines.append(line[:split_index])\n",
    "            line = line[split_index:].lstrip()\n",
    "        lines.append(line)\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# Function to query the chatbot\n",
    "def ask_chatbot(question, width=80):\n",
    "    result = qa_chain(question)\n",
    "\n",
    "    # Response\n",
    "    response = result['result']\n",
    "\n",
    "    # Source documents\n",
    "    source_documents = result['source_documents']\n",
    "    \n",
    "    # Format and return the response\n",
    "    return format_text(response, width), source_documents\n",
    "\n",
    "\n",
    "# Function to warm up the LLM and reduce latency\n",
    "def warm_up_chatbot():\n",
    "    try:\n",
    "        # Minimal request to warm up the LLM\n",
    "        response = qa_chain(\"Wie geht es dir?\")\n",
    "        print(\"LLM warmed up successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error warming up LLM: {str(e)}\")\n",
    "_ = ask_chatbot(\"Warm up!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18b465",
   "metadata": {},
   "source": [
    "## Function for audio response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd85778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display, clear_output\n",
    "from openai import OpenAI\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def openai_text_to_audio_with_widget(text, voice='onyx', speed=1.0):\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Create TTS request\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=voice,\n",
    "        input=text,\n",
    "        speed=speed\n",
    "    )\n",
    "\n",
    "    # Manually stream audio and save it to a file\n",
    "    audio_file = \"../../data/processed/temp_speech.mp3\"\n",
    "    with open(audio_file, \"wb\") as f:\n",
    "        for chunk in response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "    \n",
    "    # Create audio player widget\n",
    "    audio = Audio(audio_file, autoplay=True)\n",
    "    \n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25ac1a",
   "metadata": {},
   "source": [
    "## Ask your Chatbot for Career Advice ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58df758",
   "metadata": {},
   "source": [
    "### Occupation-based ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a43c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Clear output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Your question\n",
    "response, source_docs = ask_chatbot(\"\"\"Was macht ein Architekt?\n",
    "                                       Welche Fähigkeiten sind wichtig?\n",
    "                                       Welche Karrierepfade gibt es?\n",
    "                                       Welche verwandten Berufe gibt es?\"\"\")\n",
    "\n",
    "# Show response\n",
    "print(f\"Chatbot: {response}\", \"\\n\")\n",
    "\n",
    "# Play response as audio\n",
    "# openai_text_to_audio_with_widget(response, voice='onyx', speed=1.2)\n",
    "\n",
    "# Print source documents in a readable format\n",
    "# for i, doc in enumerate(source_docs):\n",
    "#     print(f\"Document {i+1}:\")\n",
    "#     print(f\"Source: {doc.metadata.get('name', 'Unknown')}\")\n",
    "#     print(f\"Content (excerpt): {doc.page_content[:200]}...\")\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc3aab",
   "metadata": {},
   "source": [
    "### Skill-based ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21562a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Clear output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Your question\n",
    "response, source_docs = ask_chatbot(\"\"\"Welche Berufe gibt es für meine Fähigkeiten?:\n",
    "                                       - bin gerne draussen\n",
    "                                       - kann gut mit Tieren umgehen\n",
    "                                       - kann gut mit Maschinen umgehen, z.B. Traktor fahren\n",
    "                                       - habe erste Erfahrungen mit Gemüseanbau\n",
    "                                       - habe Erfahrungen mit Holzarbeiten\"\"\")\n",
    "\n",
    "# Show response\n",
    "print(f\"Chatbot: {response}\", \"\\n\")\n",
    "\n",
    "# Play response as audio\n",
    "# openai_text_to_audio_with_widget(response, voice='onyx', speed=1.2)\n",
    "\n",
    "# Print source documents in a readable format\n",
    "# for i, doc in enumerate(source_docs):\n",
    "#     print(f\"Document {i+1}:\")\n",
    "#     print(f\"Source: {doc.metadata.get('name', 'Unknown')}\")\n",
    "#     print(f\"Content (excerpt): {doc.page_content[:200]}...\")\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf055661",
   "metadata": {},
   "source": [
    "### CV-based ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Clear output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Load CV PDF file)\n",
    "pdf_file_path = path + \"/data/raw/cv_hanna_krause.pdf\"\n",
    "\n",
    "# Read PDF file and extract text\n",
    "try:\n",
    "    with open(pdf_file_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        cv_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            cv_text += page.extract_text()\n",
    "    \n",
    "    # Close the file\n",
    "    file.close()\n",
    "\n",
    "    # Format text\n",
    "    cv_text = cv_text.strip()\n",
    "    cv_text = textwrap.fill(cv_text, width=80)\n",
    "    print(\"CV Text:\")\n",
    "    print(cv_text)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {pdf_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the PDF: {e}\")\n",
    "\n",
    "# Your question\n",
    "response, source_docs = ask_chatbot(f\"\"\"Welche Vorschläge für meine weitere Kariere \n",
    "                                        auf der Basis der Infos aus meinem CV hast Du? \n",
    "                                        Du findest meinen CV hier: {cv_text}\"\"\")\n",
    "\n",
    "# Show response\n",
    "print(\"\\n\")\n",
    "print(f\"Chatbot: {response}\", \"\\n\")\n",
    "\n",
    "# Play response as audio\n",
    "# openai_text_to_audio_with_widget(response, voice='onyx', speed=1.2)\n",
    "\n",
    "# Print source documents in a readable format\n",
    "# for i, doc in enumerate(source_docs):\n",
    "#     print(f\"Document {i+1}:\")\n",
    "#     print(f\"Source: {doc.metadata.get('name', 'Unknown')}\")\n",
    "#     print(f\"Content (excerpt): {doc.page_content[:200]}...\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# Print prompt used\n",
    "# print(\"\\nPrompt used:\")\n",
    "# print(qa_chain.prompt.messages[0].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.12 ('esi-001')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "70b29d8b2c49042bf18c3ed9f91cd97fb75a2963a1be2dca66762440606e7c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
